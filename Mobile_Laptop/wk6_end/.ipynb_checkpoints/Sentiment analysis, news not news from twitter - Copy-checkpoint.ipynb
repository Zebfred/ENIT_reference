{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional,Flatten,Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(tweets):\n",
    "    for remove in map(lambda r: re.compile(re.escape(r)), [',', ':', '\\'', '=', '&', ';', '%', '$',\n",
    "                                                            '@', '%', '^', '*', '(',')', '{','}',\n",
    "                                                            '[',' ]', '|', '/', '\\\\', '>', '<', '-',\n",
    "                                                            '!', '?', '.', \"'\", ' — ', ' — -', '#']):\n",
    "         tweets.replace(remove, '', inplace=True)\n",
    "    return tweets\n",
    "                                                           \n",
    "def remove_tags(text):\n",
    "     return re.compile(r'<[^>]+>').sub('', text)\n",
    "\n",
    "def remove_num(text):\n",
    "     return ''.join(re.sub(r'([0–9]+)','',text))\n",
    "                                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('uw.csv', encoding='mac_roman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Input=data.Input.apply(lambda x : remove_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Input=data.Input.apply(lambda x : remove_num(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       screams in 25 different languages\n",
       "1       Families to sue over Legionnaires More than 4 ...\n",
       "2       Pandemonium In Aba As Woman Delivers Baby With...\n",
       "3       My emotions are a train wreck My body is a tra...\n",
       "4       Alton brown just did a livestream and he burne...\n",
       "                              ...                        \n",
       "1859    Trollkrattos Juan Carlos Salvador The Secret T...\n",
       "1860    devon_breneman hopefully it doesnt electrocute...\n",
       "1861    Businesses are deluged with invokces Make your...\n",
       "1862    BREAKING411 4 police officers arrested for abu...\n",
       "1863    News Refugio oil spill may have been costlier ...\n",
       "Name: Input, Length: 1864, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_special_chars(data.Input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation</th>\n",
       "      <th>Input</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>screams in 25 different languages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Families to sue over Legionnaires More than 4 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Pandemonium In Aba As Woman Delivers Baby With...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>My emotions are a train wreck My body is a tra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Alton brown just did a livestream and he burne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>0</td>\n",
       "      <td>Trollkrattos Juan Carlos Salvador The Secret T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>0</td>\n",
       "      <td>devon_breneman hopefully it doesnt electrocute...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>0</td>\n",
       "      <td>Businesses are deluged with invokces Make your...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>1</td>\n",
       "      <td>BREAKING411 4 police officers arrested for abu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>1</td>\n",
       "      <td>News Refugio oil spill may have been costlier ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1864 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Validation                                              Input  \\\n",
       "0              0                  screams in 25 different languages   \n",
       "1              1  Families to sue over Legionnaires More than 4 ...   \n",
       "2              1  Pandemonium In Aba As Woman Delivers Baby With...   \n",
       "3              0  My emotions are a train wreck My body is a tra...   \n",
       "4              0  Alton brown just did a livestream and he burne...   \n",
       "...          ...                                                ...   \n",
       "1859           0  Trollkrattos Juan Carlos Salvador The Secret T...   \n",
       "1860           0  devon_breneman hopefully it doesnt electrocute...   \n",
       "1861           0  Businesses are deluged with invokces Make your...   \n",
       "1862           1  BREAKING411 4 police officers arrested for abu...   \n",
       "1863           1  News Refugio oil spill may have been costlier ...   \n",
       "\n",
       "      Unnamed: 2 Unnamed: 3  \n",
       "0            NaN        NaN  \n",
       "1            NaN        NaN  \n",
       "2            NaN        NaN  \n",
       "3            NaN        NaN  \n",
       "4            NaN        NaN  \n",
       "...          ...        ...  \n",
       "1859         NaN        NaN  \n",
       "1860         NaN        NaN  \n",
       "1861         NaN        NaN  \n",
       "1862         NaN        NaN  \n",
       "1863         NaN        NaN  \n",
       "\n",
       "[1864 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000,lower=True,split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data['Input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(data['Input'])\n",
    "X = pad_sequences(X,maxlen=500)\n",
    "Y = data['Validation']\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(y_train, y_test):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    le.fit(y_test)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    \n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_test = prepare_targets(Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 50)           428800    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 612,353\n",
      "Trainable params: 612,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=500))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.3670 - accuracy: 0.8988 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/6\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.2979 - accuracy: 0.9080 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/6\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.2318 - accuracy: 0.9494 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/6\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.1747 - accuracy: 0.9655 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/6\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.1290 - accuracy: 0.9762 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/6\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.0946 - accuracy: 0.9785 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "history=model.fit(X_train, y_train, batch_size=128, epochs=6, validation_data=[X_test, y_test])\n",
    "#, callbacks=[es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('news_sub.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90072036]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = 'ten killed and hundreds wounded in the earthquake'\n",
    "x_1=tokenizer.texts_to_sequences([news])\n",
    "x_1 = pad_sequences(x_1,maxlen=500)\n",
    "model.predict(x_1)\n",
    "#the output is closer to 1 for news\n",
    "#and closer to zero for not news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07486376]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news2 = 'going to the beach this weekend'\n",
    "x_2=tokenizer.texts_to_sequences([news2])\n",
    "x_2 = pad_sequences(x_2,maxlen=500)\n",
    "model.predict(x_2)\n",
    "#the output is closer to 1 for news\n",
    "#and closer to zero for not news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
