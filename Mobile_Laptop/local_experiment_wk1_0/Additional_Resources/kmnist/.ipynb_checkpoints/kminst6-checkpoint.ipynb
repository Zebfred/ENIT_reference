{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_train = np.load('kmnist-train-imgs.npz', allow_pickle=True)\n",
    "lst = data_train.files\n",
    "\n",
    "#for item in lst:\n",
    "#    print(item)\n",
    "#    print(data_train[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_test = np.load('kmnist-test-imgs.npz', allow_pickle=True)\n",
    "lst = data_test.files\n",
    "\n",
    "#for item in lst:\n",
    "#    print(item)\n",
    "#    print(data_test[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_test_label = np.load('kmnist-test-labels.npz', allow_pickle=True)\n",
    "lst = data_test_label.files\n",
    "\n",
    "#for item in lst:\n",
    "#    print(item)\n",
    "#    print(data_test_label[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_train_labels = np.load('kmnist-train-labels.npz', allow_pickle=True)\n",
    "lst = data_train_labels.files\n",
    "\n",
    "#for item in lst:\n",
    "#    print(item)\n",
    "#    print(data_train_labels[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('kmnist-train-imgs.npz')['arr_0']\n",
    "train_labels = np.load('kmnist-train-labels.npz')['arr_0']\n",
    "test_data = np.load('kmnist-test-imgs.npz')['arr_0']\n",
    "test_labels = np.load('kmnist-test-labels.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data[:,-1].shape)\n",
    "X = train_data[:, -1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels.shape)\n",
    "y = train_labels\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], c = y, alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussNB():\n",
    "    def fit(self, X, y, epsilon = 1e-3):\n",
    "        self.likelihoods = dict()\n",
    "        self.priors = dict()\n",
    "        \n",
    "        self.K = set(y.astype(int))\n",
    "        \n",
    "        for k in self.K:\n",
    "            X_k = X[y == k,:]\n",
    "            self.likelihoods[k] = {\"mean\":X_k.mean(axis = 0), \"cov\":X_k.var(axis = 0) + epsilon}\n",
    "            self.priors[k] = len(X_k)/len(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        N,D = X.shape\n",
    "        P_hat = np.zeros((N, len(self.K)))\n",
    "        \n",
    "        for k, l in self.likelihoods.items():\n",
    "            P_hat[:,k] = mvn.logpdf(X, l[\"mean\"], l[\"cov\"]) + np.log(self.priors[k])\n",
    "            \n",
    "        return P_hat.argmax(axis = 1)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
