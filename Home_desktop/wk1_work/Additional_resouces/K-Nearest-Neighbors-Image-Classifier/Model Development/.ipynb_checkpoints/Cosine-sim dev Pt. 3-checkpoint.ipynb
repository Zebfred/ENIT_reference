{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continueing Cosine Similarity Model Improvement\n",
    "In this notebook I will just be continueing the work from the latest version of the model in the last notebook.\n",
    "\n",
    "Here will be focusing on:\n",
    "* Furthur optimization\n",
    "* See how the model performs on less data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cupy as cp\n",
    "import heapq\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import datasets, model_selection\n",
    "mnist = datasets.fetch_mldata('MNIST original')\n",
    "\n",
    "data, target = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below Is the latest version of the algorithm, version 4, optimized and simplified more from version 3 on the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classif(comparisons, n):\n",
    "    \"\"\"comparisons: the number of numbers to test\n",
    "    n: number of top highest indices to vote on\n",
    "    returns: amount of correct predictions, total predictions, and percentage accuracy of predictions, \n",
    "    \"\"\"\n",
    "    \n",
    "    # find random images to test\n",
    "    random_indx = np.random.choice(len(target), comparisons, replace=False)\n",
    "    X = [data[i] for i in random_indx]\n",
    "    \n",
    "    # comparisons x size data structure\n",
    "    cosim = cosine_similarity(X, data)\n",
    "    \n",
    "    # get top most similar image indices, excluding most similar as that is the tested image\n",
    "    top = [(heapq.nlargest((n+1), range(len(i)), i.take)) for i in cosim]\n",
    "    top = [[target[j] for j in i[1:(n+1)]] for i in top]\n",
    "    \n",
    "    # given top most similar, vote on what input is\n",
    "    pred = [max(set(i), key=i.count) for i in top]\n",
    "    pred = np.array(pred)\n",
    "    \n",
    "    # use target labels to check accuracy\n",
    "    correct_classification = [target[i] for i in random_indx]\n",
    "    correct_classification = np.array(correct_classification)\n",
    "    \n",
    "    correct = np.count_nonzero(pred == correct_classification)\n",
    "    total = len(correct_classification)\n",
    "            \n",
    "    acc = (correct / total) * 100\n",
    "    \n",
    "    return correct, total, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 32s, sys: 1.76 s, total: 6min 34s\n",
      "Wall time: 6min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9768, 10000, 97.68)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classif(10000, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now the algorithm is much more optimized than it was in [version 1], and scales to larget comparisons far better than any previous algorithm.  This algorithm is still by no means perfect, but I will leave it for now and keep experimenting.\n",
    "\n",
    "Next, I will start building smaller datasets out of the original dataset, by pulling images randomely, and see how the algorithm performs on smaller datasets, watching what happens to the average accuracy.  I will be building smaller testing datasets going down by 10,000 with each step, that I will be running the algorithm on and seeing how accuracy degrades as number of comparison images shrinks.  I will initially make a random array, and then for every step down in data size I will just take the indices from that array so that the data tested on stays relatively constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixty_indx = np.random.choice(len(target), 60000, replace=False)\n",
    "sixty_img = [data[i] for i in sixty_indx]\n",
    "sixty_img = np.array(sixty_img)\n",
    "sixty_target = [target[i] for i in sixty_indx]\n",
    "sixty_target = np.array(sixty_target)\n",
    "sixty_img.shape, sixty_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifty_indx = sixty_indx[:50000]\n",
    "fifty_img = [data[i] for i in fifty_indx]\n",
    "fifty_img = np.array(fifty_img)\n",
    "fifty_target = [target[i] for i in fifty_indx]\n",
    "fifty_target = np.array(fifty_target)\n",
    "fifty_img.shape, fifty_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 784), (40000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourty_indx = sixty_indx[:40000]\n",
    "fourty_img = [data[i] for i in fourty_indx]\n",
    "fourty_img = np.array(fourty_img)\n",
    "fourty_target = [target[i] for i in fourty_indx]\n",
    "fourty_target = np.array(fourty_target)\n",
    "fourty_img.shape, fourty_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 784), (30000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirty_indx = sixty_indx[:30000]\n",
    "thirty_img = [data[i] for i in thirty_indx]\n",
    "thirty_img = np.array(thirty_img)\n",
    "thirty_target = [target[i] for i in thirty_indx]\n",
    "thirty_target = np.array(thirty_target)\n",
    "thirty_img.shape, thirty_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 784), (20000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_indx = sixty_indx[:20000]\n",
    "twenty_img = [data[i] for i in twenty_indx]\n",
    "twenty_img = np.array(twenty_img)\n",
    "twenty_target = [target[i] for i in twenty_indx]\n",
    "twenty_target = np.array(twenty_target)\n",
    "twenty_img.shape, twenty_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_indx = sixty_indx[:10000]\n",
    "ten_img = [data[i] for i in ten_indx]\n",
    "ten_img = np.array(ten_img)\n",
    "ten_target = [target[i] for i in ten_indx]\n",
    "ten_target = np.array(ten_target)\n",
    "ten_img.shape, ten_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 784), (5000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_indx = sixty_indx[:5000]\n",
    "five_img = [data[i] for i in five_indx]\n",
    "five_img = np.array(five_img)\n",
    "five_target = [target[i] for i in five_indx]\n",
    "five_target = np.array(five_target)\n",
    "five_img.shape, five_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 784), (1000,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_indx = sixty_indx[:1000]\n",
    "one_img = [data[i] for i in one_indx]\n",
    "one_img = np.array(one_img)\n",
    "one_target = [target[i] for i in one_indx]\n",
    "one_target = np.array(one_target)\n",
    "one_img.shape, one_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 784), (200,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twohun_indx = sixty_indx[:200]\n",
    "twohun_img = [data[i] for i in twohun_indx]\n",
    "twohun_img = np.array(twohun_img)\n",
    "twohun_target = [target[i] for i in twohun_indx]\n",
    "twohun_target = np.array(twohun_target)\n",
    "twohun_img.shape, twohun_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now alter method to take dataset and test on above dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_classif(comparisons, n, dataset, targetset):\n",
    "    \"\"\"comparisons: the number of numbers to test\n",
    "    n: number of top highest indices to vote on\n",
    "    dataset: takes dataset to test on\n",
    "    returns: amount of correct predictions, total predictions, and percentage accuracy of predictions, \n",
    "    \"\"\"\n",
    "    \n",
    "    # find random images to test\n",
    "    random_indx = np.random.choice(len(dataset), comparisons, replace=False)\n",
    "    X = [dataset[i] for i in random_indx]\n",
    "    \n",
    "    # comparisons x size data structure\n",
    "    cosim = cosine_similarity(X, dataset)\n",
    "    \n",
    "    # get top most similar image indices, excluding most similar as that is the tested image\n",
    "    top = [(heapq.nlargest((n+1), range(len(i)), i.take)) for i in cosim]\n",
    "    top = [[targetset[j] for j in i[1:(n+1)]] for i in top]\n",
    "    \n",
    "    # given top most similar, vote on what input is\n",
    "    pred = [max(set(i), key=i.count) for i in top]\n",
    "    pred = np.array(pred)\n",
    "    \n",
    "    # use target labels to check accuracy\n",
    "    correct_classification = [targetset[i] for i in random_indx]\n",
    "    correct_classification = np.array(correct_classification)\n",
    "    \n",
    "    correct = np.count_nonzero(pred == correct_classification)\n",
    "    total = len(correct_classification)\n",
    "            \n",
    "    acc = (correct / total) * 100\n",
    "    \n",
    "    return correct, total, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.4 s, sys: 456 ms, total: 40.8 s\n",
      "Wall time: 37.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(978, 1000, 97.8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, sixty_img, sixty_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 s, sys: 340 ms, total: 34.3 s\n",
      "Wall time: 31.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(975, 1000, 97.5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, fifty_img, fifty_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.1 s, sys: 304 ms, total: 27.4 s\n",
      "Wall time: 25.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(980, 1000, 98.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, fourty_img, fourty_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 s, sys: 240 ms, total: 20.7 s\n",
      "Wall time: 19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 1000, 96.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, thirty_img, thirty_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 164 ms, total: 13.9 s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(956, 1000, 95.6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, twenty_img, twenty_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.19 s, sys: 100 ms, total: 7.29 s\n",
      "Wall time: 6.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(957, 1000, 95.7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, ten_img, ten_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 s, sys: 79.8 ms, total: 4.08 s\n",
      "Wall time: 3.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(939, 1000, 93.89999999999999)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, five_img, five_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 47.8 ms, total: 1.17 s\n",
      "Wall time: 675 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(892, 1000, 89.2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, one_img, one_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 170 ms, sys: 16.1 ms, total: 186 ms\n",
      "Wall time: 66 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(151, 200, 75.5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(200, 3, twohun_img, twohun_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, as the dataset size decreases, so does accuracy. However, accuracy drops much less than what would be expected, only dropping a little less than 3% for a large drop in the data it has available from 70,000 to 10,000. What is more remarkable is that with a dataset of size only 1000, accuracy is still around 90%.  The funniest part is that the simple MNIST CNN (see notebook) only has a 85% accuracy on about 55,000 examples of the MNIST dataset, a worse accuracy than this simple similarity model on just 1000 samples.  Granted, the MNIST CNN is very simple and has a ton of ways it could be improved, and the data the CNN was trained/validated on is of slightly different composition then this scikit-learn dataset I used, however the CNN still acts as a solid benchmark.\n",
    "\n",
    "That just about wraps up the analysis I will be doing here.  Note, that while this technique worked very well on the MNIST dataset, it is highly unlikely that it will work just as well on more complicated image datasets, however it is always worth a shot so I will be trying that out later.\n",
    "\n",
    "improvements and things to think about:\n",
    "* weighted voting\n",
    "* maxpooling\n",
    "* put all the datasets into one tensor\n",
    "* algorithm seems to be similar in some ways to k-means clustering and k-nearest neighbor\n",
    "* these results are certainly not state of the art, however they are interesting and provide several lessons\n",
    "* Most CNN's are far better than the one I used and get higher testing accuracy, and are thus better than this \"classifier\".  However they don't work as well on so little data, and are far heavier etc.  This is also a \"lazy classifier\" in that no training is required\n",
    "* turns out this model is K nearest neighbor.  Same idea, take a distance metric, and then classify the point by voting with the most similar points or vectors.\n",
    "* could try cross validation to find the best n parameter\n",
    "* supposedly humans get about 97.5% accuracy on MNIST\n",
    "\n",
    "Some PCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_pca(data, k):\n",
    "    \"\"\"Reduce DATA using its K principal components.\"\"\"\n",
    "    data = data.astype(\"float64\")\n",
    "    data -= np.mean(data, axis=0)\n",
    "    U, S, V = np.linalg.svd(data, full_matrices=False)\n",
    "    return U[:,:k].dot(np.diag(S)[:k,:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = svd_pca(data, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.6 s, sys: 441 ms, total: 44 s\n",
      "Wall time: 40.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(977, 1000, 97.7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_classif(1000, 3, dfg, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't really make much of a difference, in speed or accuracy, even when shrink data to much lower dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
