{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized K-NN Algorithm\n",
    "In this notebook I implement a \"randomized\" K-NN model that classifies objects through partitioning its data into groups, then taking random samples of each of those groups, and useing sum and average to determine what class the new data point belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(\"mnist_train.csv\", \n",
    "                        delimiter=\",\")\n",
    "test_data = np.loadtxt(\"mnist_test.csv\", \n",
    "                       delimiter=\",\")\n",
    "\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_labels = np.asfarray(test_data[:, :1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First want to sort the labels while keeping track of their original indices, from there can partition everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to produce sorted index list and dictionary                    \n",
    "\n",
    "def make_partitions(train_labels):\n",
    "    value_list = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    for i in range(0, len(train_labels)):\n",
    "        insertion_indx = train_labels[i]\n",
    "        insertion_indx = int(insertion_indx)\n",
    "        value_list[insertion_indx].append(i)\n",
    "        \n",
    "    return value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_list = make_partitions(train_labels)\n",
    "value_list = np.array(value_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our partitioned data, where each partition contains the indices of that point.  So now we need to create the algorithm, which makes a random vector the size of k, and then it iterates through those indices in each partition, using cosine similarity to measure values between passed point and vectors in correspoinding data set.  Makes a vector of all the distance values for each partition.  Then, it takes each distance vector for each partition, and takes the sum and average.  Because it is cosine similarity, the largest sum and largest average win, and if the highest sum partition does not equal the highest average parition, it \"re-rolls\" by calling itself again to create a new random vector, and it does this until it finds agreement.  When highest sum is the same partition as highest average, then the corresponding partition is the label of the new point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k, classify_point, value_list, train_data):\n",
    "    \n",
    "    # random vector for getting arbitrary k number of indices form each partition\n",
    "    rand_vec = np.random.randint(1, 5300, k)\n",
    "    \n",
    "    distances = [[],[],[],[],[],[],[],[],[],[]]\n",
    "    \n",
    "    # create double for loop to iterate through the value_list and rand_vec and take distances of each\n",
    "    for i in range(0, value_list.shape[0]):\n",
    "        for j in rand_vec:\n",
    "            \n",
    "            curr_indx = value_list[i][j]\n",
    "            curr_point = train_data[curr_indx]\n",
    "            \n",
    "            curr_point = curr_point.reshape(1, -1)\n",
    "            classify_point = classify_point.reshape(1, -1)\n",
    "            \n",
    "            dist = cosine_similarity(curr_point, classify_point)\n",
    "            \n",
    "            distances[i].append(dist[0][0])\n",
    "       \n",
    "    maximum = []\n",
    "    \n",
    "    for i in distances:\n",
    "        ma = max(i)\n",
    "        maximum.append(ma)\n",
    "    \n",
    "    max_indx = np.argmax(maximum)\n",
    "    return max_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([1.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = knn(10, test_data[5], value_list, train_data)\n",
    "pred, test_labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we test the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7546 10000\n",
      "CPU times: user 2min, sys: 260 ms, total: 2min\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "correct = 0\n",
    "for i in range(0, len(test_labels)):\n",
    "    pred = knn(10, test_data[i], value_list, train_data)\n",
    "    actual = test_labels[i]\n",
    "    if(pred == actual):\n",
    "        correct += 1\n",
    "print(correct, len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8703 10000\n",
      "CPU times: user 9min 56s, sys: 776 ms, total: 9min 57s\n",
      "Wall time: 9min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "correct = 0\n",
    "for i in range(0, len(test_labels)):\n",
    "    pred = knn(50, test_data[i], value_list, train_data)\n",
    "    actual = test_labels[i]\n",
    "    if(pred == actual):\n",
    "        correct += 1\n",
    "print(correct, len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8980 10000\n",
      "CPU times: user 19min 52s, sys: 1.26 s, total: 19min 53s\n",
      "Wall time: 19min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "correct = 0\n",
    "for i in range(0, len(test_labels)):\n",
    "    pred = knn(100, test_data[i], value_list, train_data)\n",
    "    actual = test_labels[i]\n",
    "    if(pred == actual):\n",
    "        correct += 1\n",
    "print(correct, len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "correct = 0\n",
    "for i in range(0, len(test_labels)):\n",
    "    pred = knn(500, test_data[i], value_list, train_data)\n",
    "    actual = test_labels[i]\n",
    "    if(pred == actual):\n",
    "        correct += 1\n",
    "print(correct, len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "correct = 0\n",
    "for i in range(0, len(test_labels)):\n",
    "    pred = knn(700, test_data[i], value_list, train_data)\n",
    "    actual = test_labels[i]\n",
    "    if(pred == actual):\n",
    "        correct += 1\n",
    "print(correct, len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is also quite fast, however it is not very accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
