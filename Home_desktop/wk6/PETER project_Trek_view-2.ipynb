{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P.E.T.E.R  son of S.T.E.V.E not Parker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SW_All.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f8e07ef6aac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfileref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SW_All.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstar_wars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#fileref.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SW_All.txt'"
     ]
    }
   ],
   "source": [
    "fileref = open('SW_All.txt', 'r', encoding=\"utf8\")\n",
    "star_wars = fileref.read()\n",
    "#fileref.close()\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/zebfred/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#star_wars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make words lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_wars = star_wars.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#star_wars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove symbols and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_wars=\"\".join([char for char in star_wars if char not in string.punctuation and char not in string.digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#star_wars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove possible links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_wars = re.sub(r'http\\S+', '', star_wars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#star_wars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words & tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.append('�')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherlist = [\"’\",\"i'll\",\"you'll\",\"he'll\",\"she'll\",\"it'll\",\"we'll\",\"they'll\",\n",
    "                 \"i've\",\"you've\",\"he've\",\"she've\",\"it've\",\"we've\",\"they've\",\n",
    "                 \"i'd\",\"you'd\",\"he'd\",\"she'd\",\"it'd\",\"we'd\",\"they'd\", \"i'm\"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in otherlist:\n",
    "    stop_words.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_wars = word_tokenize(star_wars)\n",
    "print('# of words before filtering: ', len(star_wars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [word for word in star_wars if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = DataFrame(filtered_words,columns=['words'])\n",
    "filtered_df.to_csv('filtered_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of words after filtering: ', len(filtered_words))\n",
    "print('Loss Percentage: ', \"{:.2f}\".format((100-(len(filtered_words)/len(star_wars))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "for i in filtered_words:\n",
    "    if i not in my_dict:\n",
    "        my_dict[i] = 1\n",
    "    else:\n",
    "        my_dict[i] = my_dict[i] + 1\n",
    "        \n",
    "my_list = []        \n",
    "for i in my_dict:\n",
    "    my_list.append([i, my_dict[i]])\n",
    "\n",
    "#print(sorted(my_list))\n",
    "\n",
    "def Sort(sub_li): \n",
    "  \n",
    "    sub_li.sort(key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sub_li \n",
    "\n",
    "Sort(my_list)\n",
    "\n",
    "for i in my_list:\n",
    "    print(i)\n",
    "\n",
    "occurr = {1:0, 2:0, 4:0, 8:0, 16:0, 32:0, 64:0, 128:0, 256:0, 512:0, 1024:0, 1025:0}\n",
    "percent = {}\n",
    "\n",
    "for i in my_list:\n",
    "    if i[1] == 1:\n",
    "        occurr[1] = occurr[1] + 1\n",
    "    elif i[1] == 2:\n",
    "        occurr[2] = occurr[2] + 1\n",
    "    elif i[1] <= 4:\n",
    "        occurr[4] = occurr[4] + 1\n",
    "    elif i[1] <= 8:\n",
    "        occurr[8] = occurr[8] + 1    \n",
    "    elif i[1] <= 16:\n",
    "        occurr[16] = occurr[16] + 1\n",
    "    elif i[1] <= 32:\n",
    "        occurr[32] = occurr[32] + 1  \n",
    "    elif i[1] <= 64:\n",
    "        occurr[64] = occurr[64] + 1\n",
    "    elif i[1] <= 128:\n",
    "        occurr[128] = occurr[128] + 1  \n",
    "    elif i[1] <= 256:\n",
    "        occurr[256] = occurr[256] + 1\n",
    "    elif i[1] <= 512:\n",
    "        occurr[512] = occurr[512] + 1\n",
    "    elif i[1] <= 1024:\n",
    "        occurr[1024] = occurr[1024] + 1\n",
    "    elif i[1] >= 1025:\n",
    "        occurr[1025] = occurr[1025] + 1 \n",
    "\n",
    "for i in occurr:\n",
    "    percent[str(i)] = float(\"{:.2f}\".format((occurr[i] / len(my_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = DataFrame(my_list,columns=['Word','Frequency'])\n",
    "word_count.to_csv('word_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = pd.DataFrame(list(occurr.items()),columns = ['Frequency','Total'])\n",
    "frequency.to_csv('frequency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = pd.DataFrame(list(percent.items()),columns = ['Frequency','Percentage'])\n",
    "percentage.to_csv('percentage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = percent.keys()\n",
    "values = percent.values()\n",
    "\n",
    "plt.bar(keys, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform in stem(root) words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = [porter.stem(word) for word in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the word family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pos_tag(filtered_words)\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
