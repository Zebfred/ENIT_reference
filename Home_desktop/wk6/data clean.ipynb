{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('uw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileref = open('english3.txt', 'r', encoding=\"utf8\")\n",
    "all_words = fileref.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = word_tokenize(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    html_free = soup.get_text()\n",
    "    return html_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation and c not in string.digits])\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_not_english(text):\n",
    "    eng_only = [w for w in text if w in all_words]\n",
    "    return eng_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      screams in  different languages\n",
       "1    Families to sue over Legionnaires More than  f...\n",
       "2    Pandemonium In Aba As Woman Delivers Baby With...\n",
       "3    My emotions are a train wreck My body is a tra...\n",
       "4    Alton brown just did a livestream and he burne...\n",
       "Name: clean, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df['Input'].apply(lambda x: remove_punctuation(x))\n",
    "df['clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = df['clean'].apply(lambda x: remove_html(x))\n",
    "#df['Input'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [screams, in, different, languages]\n",
       "1       [families, to, sue, over, legionnaires, more, ...\n",
       "2       [pandemonium, in, aba, as, woman, delivers, ba...\n",
       "3       [my, emotions, are, a, train, wreck, my, body,...\n",
       "4       [alton, brown, just, did, a, livestream, and, ...\n",
       "                              ...                        \n",
       "1859    [trollkrattos, juan, carlos, salvador, the, se...\n",
       "1860    [devonbreneman, hopefully, it, doesnt, electro...\n",
       "1861    [businesses, are, deluged, with, invokces, mak...\n",
       "1862    [breaking, police, officers, arrested, for, ab...\n",
       "1863    [news, refugio, oil, spill, may, have, been, c...\n",
       "Name: clean, Length: 1864, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df['clean'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [screams, different, languages]\n",
       "1       [families, sue, legionnaires, families, affect...\n",
       "2       [pandemonium, aba, woman, delivers, baby, with...\n",
       "3       [emotions, train, wreck, body, train, wreck, i...\n",
       "4       [alton, brown, livestream, burned, butter, tou...\n",
       "                              ...                        \n",
       "1859    [trollkrattos, juan, carlos, salvador, secret,...\n",
       "1860    [devonbreneman, hopefully, doesnt, electrocute...\n",
       "1861    [businesses, deluged, invokces, make, stand, c...\n",
       "1862    [breaking, police, officers, arrested, abusing...\n",
       "1863    [news, refugio, oil, spill, may, costlier, big...\n",
       "Name: clean, Length: 1864, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df['clean'].apply(lambda x: remove_stopwords(x))\n",
    "df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [screams, different, languages]\n",
       "1       [families, sue, legionnaires, families, affect...\n",
       "2       [pandemonium, aba, woman, delivers, baby, with...\n",
       "3       [emotions, train, wreck, body, train, wreck, w...\n",
       "4       [alton, brown, burned, butter, touched, hot, p...\n",
       "                              ...                        \n",
       "1859    [juan, carlos, salvador, secret, tips, get, ri...\n",
       "1860            [hopefully, electrocute, heated, blanket]\n",
       "1861    [businesses, deluged, make, stand, colour, lik...\n",
       "1862    [breaking, police, officers, arrested, abusing...\n",
       "1863    [news, oil, spill, may, costlier, bigger, proj...\n",
       "Name: clean, Length: 1864, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean'] = df['clean'].apply(lambda x: remove_not_english(x))\n",
    "df['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   scream differ languag\n",
       "1       famili sue legionnair famili affect fatal outb...\n",
       "2       pandemonium aba woman deliv babi without face ...\n",
       "3                 emot train wreck bodi train wreck wreck\n",
       "4       alton brown burn butter touch hot plate soon m...\n",
       "                              ...                        \n",
       "1859    juan carlo salvador secret tip get riot point ...\n",
       "1860                         hope electrocut heat blanket\n",
       "1861    busi delug make stand colour like rise top pay...\n",
       "1862    break polic offic arrest abus children boot ca...\n",
       "1863           news oil spill may costlier bigger project\n",
       "Name: stemmed, Length: 1864, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stemmed'] = df['clean'].apply(lambda x: word_stemmer(x))\n",
    "df['stemmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                           [scream, different, language]\n",
       "1       [family, sue, legionnaire, family, affected, f...\n",
       "2       [pandemonium, aba, woman, delivers, baby, with...\n",
       "3       [emotion, train, wreck, body, train, wreck, wr...\n",
       "4       [alton, brown, burned, butter, touched, hot, p...\n",
       "                              ...                        \n",
       "1859    [juan, carlos, salvador, secret, tip, get, rio...\n",
       "1860            [hopefully, electrocute, heated, blanket]\n",
       "1861    [business, deluged, make, stand, colour, likel...\n",
       "1862    [breaking, police, officer, arrested, abusing,...\n",
       "1863    [news, oil, spill, may, costlier, bigger, proj...\n",
       "Name: lemmazed, Length: 1864, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmazed'] = df['clean'].apply(lambda x: word_lemmatizer(x))\n",
    "df['lemmazed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('words_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
