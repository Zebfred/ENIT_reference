{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from scipy.stats import multinomial as mlvn\n",
    "from scipy.stats import bernoulli as brn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('kmnist-train-imgs.npz')['arr_0']\n",
    "train_labels = np.load('kmnist-train-labels.npz')['arr_0']\n",
    "test_data = np.load('kmnist-test-imgs.npz')['arr_0']\n",
    "test_labels = np.load('kmnist-test-labels.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train = train_data / np.linalg.norm(train_data)\n",
    "norm_train_labels = train_labels / np.linalg.norm(train_labels)\n",
    "norm_test = test_data / np.linalg.norm(test_data)\n",
    "norm_test_labels = test_labels / np.linalg.norm(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.reshape(-1, 784)\n",
    "y_train = train_labels\n",
    "x_test = test_data.reshape(-1, 784)\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussNB():\n",
    "    def fit(self, X, y, epsilon = 1e-3):\n",
    "        self.likelihoods = dict()\n",
    "        self.priors = dict()\n",
    "        \n",
    "        self.K = set(y.astype(int))\n",
    "        \n",
    "        for k in self.K:\n",
    "            X_k = X[y == k,:]\n",
    "            self.likelihoods[k] = {\"mean\":X_k.mean(axis=0), \"cov\":X_k.var(axis=0) + epsilon}\n",
    "            self.priors[k] = len(X_k)/len(X)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        N, D = X.shape\n",
    "        \n",
    "        P_hat = np.zeros((N,len(self.K)))\n",
    "        \n",
    "        for k, l in self.likelihoods.items():\n",
    "            P_hat[:,k] = mvn.logpdf(X, l[\"mean\"], l[\"cov\"]) + np.log(self.priors[k])\n",
    "        return P_hat.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "y_hat = gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    return np.mean(y == y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.466\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy(y_test, y_hat):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussBayes():\n",
    "    def fit(self, X, y, epsilon = 1e-3):\n",
    "        self.likelihoods = dict()\n",
    "        self.priors = dict()\n",
    "        \n",
    "        self.K = set(y.astype(int))\n",
    "        \n",
    "        for k in self.K:\n",
    "            X_k = X[y == k,:]\n",
    "            N_k, D = X_k.shape\n",
    "            mu_k=X_k.mean(axis=0)\n",
    "            self.likelihoods[k] = {\"mean\":X_k.mean(axis=0), \"cov\":(1/(N_k-1))*np.matmul((X_k-mu_k).T,X_k-mu_k)+ epsilon*np.identity(D)}\n",
    "            self.priors[k] = len(X_k)/len(X)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        N, D = X.shape\n",
    "        \n",
    "        P_hat = np.zeros((N,len(self.K)))\n",
    "        \n",
    "        for k, l in self.likelihoods.items():\n",
    "            P_hat[:,k] = mvn.logpdf(X, l[\"mean\"], l[\"cov\"]) + np.log(self.priors[k])\n",
    "            \n",
    "        return P_hat.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GaussBayes()\n",
    "GB.fit(x_train,y_train)\n",
    "y2_hat = GB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.585\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy(y_test, y2_hat):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenGaussBayes():\n",
    "    def fit(self, X, y, epsilon = 1e-3):\n",
    "        self.likelihoods = dict()\n",
    "        self.priors = dict()\n",
    "        \n",
    "        self.K = set(y.astype(int))\n",
    "        \n",
    "        for k in self.K:\n",
    "            X_k = X[y == k,:]\n",
    "            N_k, D = X_k.shape\n",
    "            mu_k=X_k.mean(axis=0)\n",
    "            self.likelihoods[k] = {\"mean\":X_k.mean(axis=0), \"cov\":(1/(N_k-1))*np.matmul((X_k-mu_k).T,X_k-mu_k)+ epsilon*np.identity(D)}\n",
    "            self.priors[k] = len(X_k)/len(X)\n",
    "            \n",
    "    def predict(self, X,DistFam):\n",
    "        N, D = X.shape\n",
    "        \n",
    "        P_hat = np.zeros((N,len(self.K)))\n",
    "        \n",
    "        for k, l in self.likelihoods.items():\n",
    "            P_hat[:,k] = DistFam(X, l[\"mean\"], l[\"cov\"]) + np.log(self.priors[k])\n",
    "            \n",
    "        return P_hat.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DSel(dstring):\n",
    "    if dstring==\"Gauss\" or dstring== \"Gaussian\" or dstring==\"gauss\" or dstring==\"gaussian\":return mvn.logpdf\n",
    "    if dstring==\"multi\" or dstring== \"Multinomial\" or dstring==\"multinomial\" or dstring==\"Multi\":return mlvn.logpmf   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_dist=mvn.logpdf\n",
    "GGB = GenGaussBayes()\n",
    "GGB.fit(x_train,y_train)\n",
    "y3_hat = GGB.predict(x_test,DSel(\"gauss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.585\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy(y_test, y3_hat):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenMultBayes():\n",
    "    \n",
    "    def fit(self, X, y,DisStr, epsilon = 1e-3):\n",
    "        self.likelihoods = dict()\n",
    "        self.priors = dict()\n",
    "        \n",
    "        self.K = set(y.astype(int))\n",
    "        if DisStr==\"Gauss\":\n",
    "        \n",
    "            for k in self.K:\n",
    "                X_k = X[y == k,:]\n",
    "                N_k, D = X_k.shape\n",
    "                mu_k=X_k.mean(axis=0)\n",
    "                self.likelihoods[k] = {\"mean\":X_k.mean(axis=0), \"cov\":(1/(N_k-1))*np.matmul((X_k-mu_k).T,X_k-mu_k)+ epsilon*np.identity(D)}\n",
    "                self.priors[k] = len(X_k)/len(X)\n",
    "            return\n",
    "        if DisStr==\"Multinomial\":\n",
    "            for k in self.K:\n",
    "                X_k = X[y == k,:]\n",
    "                N_k, D = X_k.shape\n",
    "                mu_k=X_k.mean(axis=0)\n",
    "                #problems here\n",
    "                self.likelihoods[k] = {\"N\":N_k, \"P\":sum(N_k/len(X))}\n",
    "                self.priors[k] = len(X_k)/len(X)\n",
    "            \n",
    "        if DisStr==\"Bernoulli\":\n",
    "            for k in self.K:\n",
    "                X_k = X[y == k,:]\n",
    "                N_k, D = X_k.shape\n",
    "               \n",
    "                self.likelihoods[k] = {\"P\":N_k/len(X)}\n",
    "                self.priors[k] = len(X_k)/len(X)\n",
    "            \n",
    "    def predict(self, X,DistStr):\n",
    "        N, D = X.shape\n",
    "        \n",
    "        if DisStr==\"Gauss\":\n",
    "            P_hat = np.zeros((N,len(self.K)))\n",
    "\n",
    "            for k, l in self.likelihoods.items():\n",
    "                P_hat[:,k] = mvn.logpdf(X, l[\"mean\"], l[\"cov\"]) + np.log(self.priors[k])\n",
    "\n",
    "            return P_hat.argmax(axis = 1)\n",
    "        \n",
    "        if DisStr==\"Multinomial\":\n",
    "            P_hat = np.zeros((N,len(self.K)))\n",
    "\n",
    "            for k, l in self.likelihoods.items():\n",
    "                P_hat[:,k] = mlvn.logpmf(X, l[\"N\"], l[\"P\"]) + np.log(self.priors[k])\n",
    "\n",
    "            return P_hat.argmax(axis = 1)\n",
    "\n",
    "        if DisStr==\"Bernoulli\":\n",
    "            P_hat = np.zeros((N,len(self.K)))\n",
    "\n",
    "            for k, l in self.likelihoods.items():\n",
    "                P_hat[:,k] = bernoulli.logpmf(X,l[\"P\"]) + np.log(self.priors[k])\n",
    "\n",
    "            return P_hat.argmax(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d60e213c938d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mGMB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenMultBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mGMB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDisStr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Multinomial'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my4_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGMB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-7e316133f243>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, DisStr, epsilon)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mmu_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[1;31m#problems here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlikelihoods\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"N\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mN_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_k\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "GMB = GenMultBayes()\n",
    "GMB.fit(x_train,y_train, DisStr='Multinomial')\n",
    "y4_hat = GMB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernNB():\n",
    "  def fit(self, X, y, epsilon = 1e-2):\n",
    "    N, D = X.shape\n",
    "    self.likelihoods = {}\n",
    "    self.priors = {}\n",
    "    self.K = set(y.astype(int))\n",
    "\n",
    "    for k in self.K:\n",
    "      X_k = X[y==k,:]\n",
    "      p = (sum(X_k)+1) / (len(X_k)+2)\n",
    "      self.likelihoods[k] = {'mean': p, 'cov': p * (1 - p) + epsilon}\n",
    "      self.priors[k] = len(X_k)/len(X)\n",
    "\n",
    "  def predict(self, X):\n",
    "    N, D = X.shape\n",
    "    P_hat = np.zeros((N, len(self.K)))\n",
    "\n",
    "    for k,l in self.likelihoods.items():\n",
    "      # Using the Bernoulli funtion/formula. Trick is to get the matrices/vectors to go from mxn to a 1x1 number for each k value.\n",
    "      P_hat[:,k] = np.log(self.priors[k]) + np.matmul(X, np.log(l['mean'])) + np.matmul((1 - X), np.log(abs(1-l['mean'])))\n",
    "\n",
    "    return P_hat.argmax(axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-f943f1a93ff0>:20: RuntimeWarning: divide by zero encountered in log\n",
      "  P_hat[:,k] = np.log(self.priors[k]) + np.matmul(X, np.log(l['mean'])) + np.matmul((1 - X), np.log(abs(1-l['mean'])))\n",
      "<ipython-input-25-f943f1a93ff0>:20: RuntimeWarning: invalid value encountered in matmul\n",
      "  P_hat[:,k] = np.log(self.priors[k]) + np.matmul(X, np.log(l['mean'])) + np.matmul((1 - X), np.log(abs(1-l['mean'])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0948\n"
     ]
    }
   ],
   "source": [
    "bnb = BernNB()\n",
    "bnb.fit(x_train,y_train) # Use the X and Y Training set here\n",
    "yb_hat = bnb.predict(x_test) # Use the X Test here\n",
    "print(accuracy(y_test, yb_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
